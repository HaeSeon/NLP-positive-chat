{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"koBERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMd5mC1Sf7C6EoO0cxtAaPj"},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c2f8a74a4fc346f29520e5cea3f6b85c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d6dc3ac696dc4e39b3b67c100f0d2cac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_99b10990255f4c6c83ddbb72ea35e23e","IPY_MODEL_e234afb283084b5791dc33807fc85aca"]}},"d6dc3ac696dc4e39b3b67c100f0d2cac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"99b10990255f4c6c83ddbb72ea35e23e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34a9882646e840f6a4c863f6b0f94b0f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b26284bbcd864292892d3e271bd6517a"}},"e234afb283084b5791dc33807fc85aca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_379b1deffec5449c978e59751abac504","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 3.12MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a2ef7e730ce48bf9a1fe855abc1689e"}},"34a9882646e840f6a4c863f6b0f94b0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b26284bbcd864292892d3e271bd6517a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"379b1deffec5449c978e59751abac504":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8a2ef7e730ce48bf9a1fe855abc1689e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ll_-UElO_xmN","executionInfo":{"status":"ok","timestamp":1607376623910,"user_tz":-540,"elapsed":9418,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"90a85ebd-3421-4769-a1ae-d50a16d69fd0"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 6.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 12.4MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Collecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.7MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=3e6154c90a3af5a0ec07db50e9d2bf7d7e4971889cf52631430da277fdb140b8\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jtFa49WBAMzy","executionInfo":{"status":"ok","timestamp":1607376630481,"user_tz":-540,"elapsed":6923,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from transformers import *\n","import json\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yt0n-71JAR2k","executionInfo":{"status":"ok","timestamp":1607376654641,"user_tz":-540,"elapsed":28740,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"7ba31766-5570-4933-e39b-5440d1bbd263"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYvBYkwwAZuF","executionInfo":{"status":"ok","timestamp":1607376657701,"user_tz":-540,"elapsed":1201,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"561ddd95-a619-40d5-af13-977bf4f5713a"},"source":["% cd 'gdrive/MyDrive/Colab Notebooks/machine-learning/BERT_AI'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Colab Notebooks/machine-learning/BERT_AI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"-mZL7X4EA6Xx","outputId":"63cb3eeb-cbd8-4f93-c8f3-9acdfa8ae14f"},"source":["!git clone https://github.com/e9t/nsmc.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fatal: destination path 'nsmc' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Ji_HAhXxBhvU","outputId":"f8cb2b56-f8ef-4ffd-c0d7-31af59e80367"},"source":["os.listdir('nsmc')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.git',\n"," 'README.md',\n"," 'code',\n"," 'ratings.txt',\n"," 'ratings_test.txt',\n"," 'ratings_train.txt',\n"," 'raw',\n"," 'synopses.json']"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"G1QQ-9W4BpO-","executionInfo":{"status":"ok","timestamp":1607376663430,"user_tz":-540,"elapsed":3814,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}}},"source":["train = pd.read_table(\"nsmc/\"+\"ratings_train.txt\")\n","test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"Op_HZ6WjBrpF","executionInfo":{"status":"ok","timestamp":1607376663810,"user_tz":-540,"elapsed":1417,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"ce349ed0-e4ad-492e-b7f7-bb8ea28ff693"},"source":["train[0:10]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>9976970</td>\n","      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3819312</td>\n","      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10265843</td>\n","      <td>너무재밓었다그래서보는것을추천한다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9045019</td>\n","      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>6483659</td>\n","      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5403919</td>\n","      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7797314</td>\n","      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>9443947</td>\n","      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7156791</td>\n","      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5912145</td>\n","      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         id                                           document  label\n","0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n","1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n","2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n","3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n","4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n","5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n","6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n","7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n","8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n","9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":67,"referenced_widgets":["c2f8a74a4fc346f29520e5cea3f6b85c","d6dc3ac696dc4e39b3b67c100f0d2cac","99b10990255f4c6c83ddbb72ea35e23e","e234afb283084b5791dc33807fc85aca","34a9882646e840f6a4c863f6b0f94b0f","b26284bbcd864292892d3e271bd6517a","379b1deffec5449c978e59751abac504","8a2ef7e730ce48bf9a1fe855abc1689e"]},"id":"gfZeF4WaB2qd","executionInfo":{"status":"ok","timestamp":1607376677692,"user_tz":-540,"elapsed":1324,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"afe99fa7-8c86-4235-ae36-dab4ccc7827e"},"source":["tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2f8a74a4fc346f29520e5cea3f6b85c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"28JJ1vFpB91S","executionInfo":{"status":"ok","timestamp":1607376697523,"user_tz":-540,"elapsed":665,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"730795c7-3d4c-46e9-fcc5-5407bc65b187"},"source":["print(tokenizer.encode(\"아 진짜 배고프다 새우크림파스타 먹고싶다아ㅏㅠㅠ\"))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[101, 9519, 9708, 119235, 9330, 11664, 28396, 11903, 9415, 27355, 20308, 67527, 46150, 12605, 22695, 100, 102]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0jjkG_KD05Q","executionInfo":{"status":"ok","timestamp":1607376708897,"user_tz":-540,"elapsed":825,"user":{"displayName":"이해선","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPhqHAnr2_4OCRXlW8UfeulK0wIAWvQsUZRfi-=s64","userId":"03483812873333221359"}},"outputId":"adc1f05f-ae54-4401-8902-74d6f1e04b2e"},"source":["print(tokenizer.tokenize(\"아 진짜 배고프다 새우크림파스타 먹고싶다아ㅏㅠㅠ\"))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['아', '진', '##짜', '배', '##고', '##프', '##다', '새', '##우', '##크', '##림', '##파', '##스', '##타', '[UNK]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Rnfdpyw6D_57","outputId":"19a7878e-2d10-41de-9225-0a2da2b5b46f"},"source":["def convert_data(data_df):\n","    global tokenizer\n","    \n","    SEQ_LEN = 128 #SEQ_LEN : 버트에 들어갈 인풋의 길이\n","    \n","    tokens, masks, segments, targets = [], [], [], []\n","    \n","    for i in tqdm(range(len(data_df))):\n","        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, truncation=True, padding='max_length')\n","       \n","        # 마스크는 토큰화한 문장에서 패딩이 있는 부분을1, 없는 부분을 0\n","        num_zeros = token.count(0)\n","        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n","        \n","        # 문장 전후관계 신경 X, 모두 0으로 채움\n","        segment = [0]*SEQ_LEN\n","        tokens.append(token)\n","        masks.append(mask)\n","        segments.append(segment)\n","        \n","        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장함\n","        targets.append(data_df[LABEL_COLUMN][i])\n","\n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    targets = np.array(targets)\n","\n","    return [tokens, masks, segments], targets\n","\n","# 위에 정의한 convert_data 함수를 불러옴\n","def load_data(pandas_dataframe):\n","    data_df = pandas_dataframe\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n","    data_x, data_y = convert_data(data_df)\n","    return data_x, data_y\n","\n","SEQ_LEN = 128\n","BATCH_SIZE = 20\n","# 문장\n","DATA_COLUMN = \"document\"\n","# 긍/부정\n","LABEL_COLUMN = \"label\"\n","\n","# train 데이터를 버트 인풋에 맞게 변환\n","train_x, train_y = load_data(train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 150000/150000 [01:03<00:00, 2371.14it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"KuZ3cUnsEqyb","outputId":"da37c45a-ce21-46b1-ec56-2c7b1bfcf887"},"source":["# 훈련 성능을 검증한 test 데이터를 버트 인풋에 맞게 변환\n","test_x, test_y = load_data(test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50000/50000 [00:20<00:00, 2474.16it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"52gZp6g3Ex3Y","outputId":"1fdcfe48-075e-458d-8505-adfe064a14fe"},"source":["# TPU 객체 지정\n","TPU = True\n","if TPU:\n","  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","  tf.config.experimental_connect_to_cluster(resolver)\n","  tf.tpu.experimental.initialize_tpu_system(resolver)\n","else:\n","  pass"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.88.37.146:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.88.37.146:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"referenced_widgets":["fc01dac391f8465086a11ba59978c2ad","5aea051182b540a28330b545871492a8"]},"id":"Bieti8p4GXmb","outputId":"96647420-f236-4462-80f9-109a31b5e52b"},"source":["model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n","# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n","token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n","bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n","# 버트 아웃풋의 텐서의 shape은 [batch_size, 문장의 길이, 768]임"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fc01dac391f8465086a11ba59978c2ad","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5aea051182b540a28330b545871492a8","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zqakaLAQGjCE"},"source":["bert_outputs = bert_outputs[1]\n","sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\n","sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n","sentiment_model.compile(optimizer=tf.keras.optimizers.Adam(lr=1.0e-5), loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"p9eK-3gSGmIg","outputId":"14add7ca-a74a-402d-f677-d0d595aa6e2d"},"source":["sentiment_model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_word_ids (InputLayer)     [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_masks (InputLayer)        [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","input_segment (InputLayer)      [(None, 128)]        0                                            \n","__________________________________________________________________________________________________\n","tf_bert_model (TFBertModel)     TFBaseModelOutputWit 177853440   input_word_ids[0][0]             \n","                                                                 input_masks[0][0]                \n","                                                                 input_segment[0][0]              \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 1)            769         tf_bert_model[0][1]              \n","==================================================================================================\n","Total params: 177,854,209\n","Trainable params: 177,854,209\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"_COJtxgDGojt"},"source":["# Rectified Adam 옵티마이저 사용\n","import tensorflow_addons as tfa\n","opt = tfa.optimizers.RectifiedAdam(lr=1.0e-5, weight_decay=0.0025)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"rMZfGJWTGqrH"},"source":["def create_sentiment_bert():\n","  # 버트 pretrained 모델 로드\n","  model = TFBertModel.from_pretrained('bert-base-multilingual-cased')\n","  \n","  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n","  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n","  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n","  # 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n","  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n","\n","  bert_outputs = bert_outputs[1]\n","  sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(bert_outputs)\n","  sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n","\n","  sentiment_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])\n","  return sentiment_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"1LtnDZtZGtA-","outputId":"2738ef79-b00d-4dd5-ff74-977585b0b6fd"},"source":["# TPU 실행 시\n","if TPU:\n","  strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","# 함수를 strategy.scope로 묶어 줌\n","  with strategy.scope():\n","    sentiment_model = create_sentiment_bert()\n","  \n","  sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=100, validation_data=(test_x, test_y))\n","else:\n","  # GPU 모드로 훈련시킬 때\n","  sentiment_model = create_sentiment_bert()\n","  \n","  sentiment_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=100, validation_data=(test_x, test_y))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n","Some layers from the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/4\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Iterator.get_next_as_optional()` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Iterator.get_next_as_optional()` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["   2/1500 [..............................] - ETA: 9:15:51 - loss: 0.6895 - accuracy: 0.5450 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.1476s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0110s vs `on_train_batch_end` time: 0.1476s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["1500/1500 [==============================] - ETA: 0s - loss: 0.4512 - accuracy: 0.7800WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_test_batch_end` time: 0.0417s). Check your callbacks.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_test_batch_end` time: 0.0417s). Check your callbacks.\n"],"name":"stderr"},{"output_type":"stream","text":["1500/1500 [==============================] - 316s 211ms/step - loss: 0.4512 - accuracy: 0.7800 - val_loss: 0.3575 - val_accuracy: 0.8402\n","Epoch 2/4\n","1500/1500 [==============================] - 261s 174ms/step - loss: 0.3361 - accuracy: 0.8499 - val_loss: 0.3301 - val_accuracy: 0.8538\n","Epoch 3/4\n","1500/1500 [==============================] - 262s 174ms/step - loss: 0.2952 - accuracy: 0.8717 - val_loss: 0.3040 - val_accuracy: 0.8663\n","Epoch 4/4\n","1500/1500 [==============================] - 262s 175ms/step - loss: 0.2602 - accuracy: 0.8892 - val_loss: 0.3107 - val_accuracy: 0.8684\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"3ECUqvrQHREY"},"source":["path = \"gdrive/MyDrive/Colab Notebooks/machine-learning/BERT_AI\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"A5OE7y9YLx6O"},"source":["sentiment_model.save_weights(\"/huggingface_bert.h5\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"pLNGXN_UNG1Y"},"source":["def predict_convert_data(data_df):\n","    global tokenizer\n","    tokens, masks, segments = [], [], []\n","    \n","    for i in tqdm(range(len(data_df))):\n","\n","        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, truncation=True, padding='max_length')\n","        num_zeros = token.count(0)\n","        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n","        segment = [0]*SEQ_LEN\n","\n","        tokens.append(token)\n","        segments.append(segment)\n","        masks.append(mask)\n","\n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    return [tokens, masks, segments]\n","\n","# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n","def predict_load_data(pandas_dataframe):\n","    data_df = pandas_dataframe\n","    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n","    data_x = predict_convert_data(data_df)\n","    return data_x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"UqsL2I4YNJaa","outputId":"8cdf80b2-330f-4a2d-a95b-1f7534a04100"},"source":["test_set = predict_load_data(test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 50000/50000 [00:21<00:00, 2339.06it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"FlYssCJINRjQ","outputId":"8f6623fc-f000-457f-a905-4a37b56eb989"},"source":["test_set"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[  101,  8911,   100, ...,     0,     0,     0],\n","        [  101,   144, 11490, ...,     0,     0,     0],\n","        [  101,  9303, 21711, ...,     0,     0,     0],\n","        ...,\n","        [  101,  8924, 67527, ...,     0,     0,     0],\n","        [  101,  9666, 14423, ...,     0,     0,     0],\n","        [  101,  9246, 32537, ...,     0,     0,     0]]),\n"," array([[1, 1, 1, ..., 0, 0, 0],\n","        [1, 1, 1, ..., 0, 0, 0],\n","        [1, 1, 1, ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1, ..., 0, 0, 0],\n","        [1, 1, 1, ..., 0, 0, 0],\n","        [1, 1, 1, ..., 0, 0, 0]]),\n"," array([[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]])]"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"9Q_8rF1PNTl4"},"source":["with strategy.scope():\n","  preds = sentiment_model.predict(test_set)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CFc6ayh5NhCu"},"source":["# 부정이면 0, 긍정이면 1 출력\n","preds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"02JHqIACNkDk"},"source":["from sklearn.metrics import classification_report\n","y_true = test['label']\n","# F1 Score 확인\n","print(classification_report(y_true, np.round(preds,0)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5u5euF2NmdR"},"source":["import logging\n","tf.get_logger().setLevel(logging.ERROR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z30owVy5Npj1"},"source":["def sentence_convert_data(data):\n","    global tokenizer\n","    tokens, masks, segments = [], [], []\n","    token = tokenizer.encode(data, max_length=SEQ_LEN, truncation=True, padding='max_length')\n","    \n","    num_zeros = token.count(0) \n","    mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros \n","    segment = [0]*SEQ_LEN\n","\n","    tokens.append(token)\n","    segments.append(segment)\n","    masks.append(mask)\n","\n","    tokens = np.array(tokens)\n","    masks = np.array(masks)\n","    segments = np.array(segments)\n","    return [tokens, masks, segments]\n","\n","def evaluation_predict(sentence):\n","    data_x = sentence_convert_data(sentence)\n","    predict = sentiment_model.predict(data_x)\n","    predict_value = np.ravel(predict)\n","    predict_answer = np.round(predict_value,0).item()\n","    \n","    if predict_answer == 0:\n","      print(\"(부정 확률 : %.2f) 부정적인 평가입니다.\" % (1-predict_value))\n","    elif predict_answer == 1:\n","      print(\"(긍정 확률 : %.2f) 긍정적인 평가입니다.\" % predict_value)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAiW2ZU2Nrrh"},"source":["evaluation_predict(\"유후ㅇ아아\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Py9n2JVNte-"},"source":["evaluation_predict(\"뭐 이딴게 다있어\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnt1tzEiN65A"},"source":["from keras.models import load_model\n","model = load_model('sentiment_model')"],"execution_count":null,"outputs":[]}]}